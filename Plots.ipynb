{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import h5py\n",
    "%matplotlib inline\n",
    "from matplotlib import rc\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pickle\n",
    "from matplotlib import cm\n",
    "import matplotlib \n",
    "import os\n",
    "import os.path\n",
    "from cycler import cycler\n",
    "rc('font',**{'family':'sans-serif', 'sans-serif':['Helvetica']})\n",
    "import pymongo\n",
    "from copy import copy\n",
    "import pandas as pd\n",
    "from matplotlib.colors import hsv_to_rgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.environ.get('BRAINSTORM_DATA_DIR')\n",
    "dataset_order = ['easy_superpos', 'bars', 'corners', 'shapes', 'mnist_shapes', 'multi_mnist_thresholded'] #, 'tetris']\n",
    "cmap = sns.cubehelix_palette(12, start=1., rot=1.5, light=.8, dark=0.2, hue=1.0, as_cmap=True)\n",
    "dataset_names = {\n",
    "    'bars': 'Bars',\n",
    "    'corners': 'Corners', \n",
    "    'easy_superpos': 'Simple Superposition',\n",
    "    'mnist_shapes': 'MNIST+Shape',\n",
    "    'multi_mnist_thresholded': 'Multi MNIST',\n",
    "    'shapes': 'Shapes'\n",
    "}\n",
    "examples = {\n",
    "    'bars': 21,\n",
    "    'bars_original': 2,\n",
    "    'corners': 23,\n",
    "    'easy_superpos': 42,\n",
    "    'multi_mnist_thresholded': 456,\n",
    "    'mnist_shapes': 100,\n",
    "    'shapes': 21\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = []\n",
    "all_groups = []\n",
    "\n",
    "for ds in dataset_order:\n",
    "    with h5py.File(os.path.join(DATA_DIR, ds + '.h5'), 'r') as f:\n",
    "        all_data.append(f['test/default'][0, examples[ds]])\n",
    "        all_groups.append(f['test/groups'][0, examples[ds]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=len(dataset_names), figsize=(5*len(dataset_names), 10))\n",
    "for i, ds in enumerate(dataset_order):\n",
    "    data = all_data[i][:, :, 0]\n",
    "    groups = all_groups[i][:, :, 0]\n",
    "    sns.heatmap(data, mask=data==0, square=True, xticklabels=False, yticklabels=False, cmap='Greys', cbar=False, ax=axes[0, i])#, linewidth=0.01)\n",
    "    sns.heatmap(groups, mask=groups==0, square=True, xticklabels=False, yticklabels=False, cmap='viridis_r', cbar=False, ax=axes[1, i])#, linewidth=0.01)\n",
    "    axes[0, i].set_title(dataset_names[ds], fontsize=24) #fontweight='bold')\n",
    "\n",
    "axes[0, 0].set_ylabel('Input Image', fontsize=18)\n",
    "axes[1, 0].set_ylabel('Ground-Truth Grouping', fontsize=18)\n",
    "plt.subplots_adjust(hspace=0.05, wspace=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig.savefig('figures/dataset_preview.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Predictability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 23\n",
    "with h5py.File(os.path.join(DATA_DIR, 'shapes.h5'), 'r') as f:\n",
    "    x = f['test/groups'][0, i, :, :, 0]\n",
    "\n",
    "def build_checkerboard(w, h) :\n",
    "    re = np.r_[ w*[0,1] ]        # even-numbered rows\n",
    "    ro = np.r_[ w*[1,0] ]        # odd-numbered rows\n",
    "    return np.row_stack(h*(re, ro))\n",
    "    \n",
    "corrupted_x = x.copy()\n",
    "corrupted_x[20:24, 8:12] *= build_checkerboard(2, 2)\n",
    "sns.heatmap(corrupted_x, mask=corrupted_x==0, square=True, xticklabels=False, yticklabels=False, cmap='viridis_r', cbar=False)#, linewidth=0.01)\n",
    "plt.savefig('figures/object_predictability.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Awesome Plot\n",
    "For this to work you must first run evaluate and produce the results files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def color_spines(ax, lw=2, color='green'):\n",
    "    for sn in ['top', 'bottom', 'left', 'right']:\n",
    "        ax.spines[sn].set_linewidth(lw)\n",
    "        ax.spines[sn].set_color(color)\n",
    "        ax.spines[sn].set_visible(True)\n",
    "\n",
    "def awesome_plot(problem, nr_iters, K, example_idxs, iterations, figsize, wspace, hspace, palette):\n",
    "    example_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I')\n",
    "    \n",
    "    results_filename = 'Results/{}_{}_{}.pickle'.format(problem, nr_iters, K)\n",
    "    with open(results_filename, 'rb') as f:\n",
    "        scores, likelihoods, results = pickle.load(f)\n",
    "\n",
    "    with h5py.File('/home/greff/Datasets/{}.h5'.format(problem)) as f:\n",
    "        data = f['test']['default'][:]\n",
    "        true_groups = f['test']['groups'][:]\n",
    "\n",
    "    sort_idxs = np.argsort(scores[:, -1, 0])\n",
    "    scores = scores[sort_idxs]\n",
    "    results = results[sort_idxs]\n",
    "    data = data[:, sort_idxs, :]\n",
    "    likelihoods = likelihoods[sort_idxs]\n",
    "    tgroups = true_groups[0, sort_idxs]\n",
    "    \n",
    "    if results.shape[-1] != 3:\n",
    "        nr_colors = results.shape[-1]\n",
    "        hsv_colors = np.ones((nr_colors, 3))\n",
    "        hsv_colors[:, 0] = (np.linspace(0, 1, nr_colors, endpoint=False) + 2/3) % 1.0\n",
    "        color_conv = hsv_to_rgb(hsv_colors)\n",
    "        results = results.reshape(-1, nr_colors).dot(color_conv).reshape(results.shape[:-1] + (3,))\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "\n",
    "    nr_examples = len(example_idxs)\n",
    "    nr_iterations = len(iterations)\n",
    "    im_size = data.shape[2]\n",
    "\n",
    "    # Set up the Grid\n",
    "    gs = gridspec.GridSpec(nr_iterations + 5, nr_examples + 2, \n",
    "                           height_ratios=[1, 0.3, 1] + [1]*nr_iterations + [0.7, 0.3], \n",
    "                           width_ratios=[1]*nr_examples + [0.1, 1])\n",
    "    gs.update(left=0.0, right=1.0, wspace=wspace, hspace=hspace)\n",
    "\n",
    "    score_ax = fig.add_subplot(gs[0, :])\n",
    "    data_axes = [fig.add_subplot(gs[2, i]) for i in range(nr_examples)]\n",
    "    iter_axes = [[fig.add_subplot(gs[iter_nr, i]) for i in range(nr_examples)] for iter_nr in range(3, nr_iterations+3)]\n",
    "    gt_axes = [fig.add_subplot(gs[nr_iterations + 3:, i]) for i in range(nr_examples)]\n",
    "    likelihood_ax = fig.add_subplot(gs[3:nr_iterations + 3, nr_examples+1])\n",
    "    final_ax = fig.add_subplot(gs[nr_iterations+3, nr_examples+1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Score and confidences \n",
    "    score_ax.plot(scores[:, -1, 0], 'k', label='score')\n",
    "    score_ax.plot(scores[:, -2, 1], 'k', alpha=0.2, label='confidence')\n",
    "    #score_ax.set_ylabel('Score')\n",
    "    score_ax.set_xticks([])\n",
    "    score_ax.set_title('Test Samples Sorted by Score')\n",
    "    score_ax.legend(loc='lower right')\n",
    "\n",
    "    # Data\n",
    "    transFigure = fig.transFigure.inverted()\n",
    "    fig.lines = []\n",
    "    for col, i in enumerate(example_idxs):\n",
    "        data_ax = data_axes[col]\n",
    "        data_ax.set_title(example_names[col], weight='bold', color=palette[col], x=0.5)\n",
    "\n",
    "        d = data[0, i, :, :, 0]\n",
    "        sns.heatmap(d, mask=d==0, square=True, xticklabels=False, yticklabels=False, \n",
    "                    cmap=cm.Greys, linewidth=0, ax=data_ax, cbar=False)\n",
    "\n",
    "        # mark the positions in the score plot\n",
    "        score_ax.axvline(x=i, color=palette[col], linewidth=0.5)\n",
    "        score_ax.plot([i], scores[i, -1, 0], 'ko')\n",
    "        score_ax.plot([i], scores[i, -1, 1], 'k.')\n",
    "\n",
    "        # Connect the plots \n",
    "        coord1 = transFigure.transform(score_ax.transData.transform([i, score_ax.get_ylim()[0]]))\n",
    "        coord2 = transFigure.transform(data_axes[col].transData.transform([im_size/2,im_size]))\n",
    "\n",
    "        line = matplotlib.lines.Line2D((coord1[0],coord2[0]),(coord1[1],coord2[1]),\n",
    "                                       transform=fig.transFigure, color=palette[col])\n",
    "        fig.lines.append(line)\n",
    "        color_spines(data_ax, color=palette[col], lw=3)\n",
    "\n",
    "    data_axes[0].set_ylabel('Input Image', labelpad=-3)\n",
    "\n",
    "    # Iterations\n",
    "    for it_nr, row_axes in zip(iterations, iter_axes):\n",
    "        for col, (ex_nr, ax) in enumerate(zip(example_idxs, row_axes)):\n",
    "            ax.imshow(results[ex_nr, it_nr, 0, :, :, 0, :], interpolation='nearest')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            #color_spines(ax, color=palette[col])\n",
    "        #row_axes[0].set_ylabel('{}'.format(it_nr))\n",
    "        \n",
    "    iter_axes[len(iter_axes)//2][0].set_ylabel('Cluster Assignments')\n",
    "\n",
    "\n",
    "    # Ground-Truth\n",
    "    for col, (ex_nr, ax) in enumerate(zip(example_idxs, gt_axes)):\n",
    "        gt = tgroups[ex_nr, :, :, 0]\n",
    "        sns.heatmap(gt, mask=gt==0, square=True, xticklabels=False, yticklabels=False,  \n",
    "                    cbar=False, cmap='viridis_r', ax=ax)#, linewidth=0.01)\n",
    "        #color_spines(ax, color=palette[col])\n",
    "    gt_axes[0].set_ylabel('Ground-Truth', labelpad=-3)\n",
    "\n",
    "\n",
    "    # likelihoods\n",
    "    x = np.arange(0, 10.5, 1.)[::-1]\n",
    "    y = likelihoods[example_idxs, ::2].T\n",
    "\n",
    "    likelihood_ax.set_prop_cycle(cycler('color', palette))\n",
    "    lines = likelihood_ax.plot(y, x)\n",
    "    likelihood_ax.legend(lines, example_names, loc='lower left')\n",
    "    likelihood_ax.yaxis.tick_right()\n",
    "    likelihood_ax.set_yticks(range(11))\n",
    "    likelihood_ax.set_yticklabels(['{}'.format(j) for j in range(0, 11)[::-1]])\n",
    "    likelihood_ax.set_ylim([-0.1, 10.1])\n",
    "    likelihood_ax.yaxis.set_label_position(\"right\")\n",
    "    likelihood_ax.set_ylabel('Iteration nr', rotation=-90, labelpad=10)\n",
    "\n",
    "    likelihood_ax.xaxis.set_label_position(\"top\")\n",
    "    likelihood_ax.xaxis.tick_top()\n",
    "    likelihood_ax.set_xlabel('log Likelihood')\n",
    "    plt.setp( likelihood_ax.xaxis.get_majorticklabels(), rotation=-90)\n",
    "    #likelihood_ax.set_xticks([-600, -400, -200, 0])\n",
    "\n",
    "    # Connect the iterations \n",
    "    for i, iter_nr in enumerate(iterations):\n",
    "        coord1 = transFigure.transform(iter_axes[i][-1].transData.transform([im_size, im_size/2]))\n",
    "        coord2 = transFigure.transform(likelihood_ax.transData.transform(\n",
    "                [likelihood_ax.get_xlim()[0], nr_iterations - iter_nr + 3]))\n",
    "\n",
    "        line = matplotlib.lines.Line2D((coord1[0],coord2[0]),(coord1[1],coord2[1]),\n",
    "                                   transform=fig.transFigure, color='k', lw=1, alpha=0.3)\n",
    "        likelihood_ax.axhline(nr_iterations - iter_nr + 3, color='k', lw=1, alpha=0.3)\n",
    "        fig.lines.append(line)\n",
    "\n",
    "    # Fat dots on top of likelihood plot\n",
    "    likelihood_ax.set_prop_cycle(cycler('color', palette))\n",
    "    likelihood_ax.plot(y[iterations], x[iterations], 'o')\n",
    "\n",
    "    # zoomed in likelihood\n",
    "    for col, final_y in enumerate(y[-1]):\n",
    "        final_ax.plot(final_y, [0], '.', color=palette[col])\n",
    "\n",
    "    final_ax.set_yticks([])\n",
    "    final_ax.set_yticklabels([])\n",
    "    final_ax.set_ylim(-0.01, 1)\n",
    "\n",
    "    for col, final_y in enumerate(y[-1]):      \n",
    "        coord1 = transFigure.transform(likelihood_ax.transData.transform([final_y, 0]))\n",
    "        coord2 = transFigure.transform(final_ax.transData.transform([final_y, 0]))\n",
    "        line = matplotlib.lines.Line2D((coord1[0],coord2[0]),(coord1[1],coord2[1]),\n",
    "                                   transform=fig.transFigure, color=palette[col])\n",
    "        fig.lines.append(line)\n",
    "    final_ax.yaxis.set_label_position(\"right\")\n",
    "    final_ax.set_ylabel('Zoomed', rotation=-90, labelpad=10)\n",
    "    plt.setp(final_ax.xaxis.get_majorticklabels(), rotation=-90)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "palette = sns.color_palette()\n",
    "sns.palplot(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = awesome_plot('shapes', 10, 3, \n",
    "                   example_idxs=[1, 200, 403, 604, 803, 999],\n",
    "                   iterations=np.array([0, 1, 2, 3, 5, 7, 10]),\n",
    "                   figsize=(8, 15),\n",
    "                   wspace=0.08,\n",
    "                   hspace=0.02,\n",
    "                   palette=palette)\n",
    "fig.savefig('figures/shapes_iter_examples.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = awesome_plot('corners', 10, 5, \n",
    "                   example_idxs=[1, 200, 400, 593, 804, 999],\n",
    "                   iterations=np.array([0, 1, 2, 3, 5, 7, 10]),\n",
    "                   figsize=(8, 15),\n",
    "                   wspace=0.08,\n",
    "                   hspace=0.02,\n",
    "                   palette=palette)\n",
    "fig.savefig('figures/corners_iter_examples.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = awesome_plot('bars', 10, 12, \n",
    "                   example_idxs=[1, 200, 400, 600, 800, 999],\n",
    "                   iterations=np.array([0, 1, 2, 3, 5, 7, 10]),\n",
    "                   figsize=(8, 15),\n",
    "                   wspace=0.08,\n",
    "                   hspace=0.02,\n",
    "                   palette=palette)\n",
    "fig.savefig('figures/bars_iter_examples.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = awesome_plot('simple_superpos', 10, 2, \n",
    "                   example_idxs=[0, 20, 60, 82, 103, 119],\n",
    "                   iterations=np.array([0, 1, 2, 3, 5, 7, 10]),\n",
    "                   figsize=(8, 15),\n",
    "                   wspace=0.08,\n",
    "                   hspace=0.02,\n",
    "                   palette=palette)\n",
    "fig.savefig('figures/simple_superpos_iter_examples.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = awesome_plot('mnist_shape', 10, 2, \n",
    "                   example_idxs=[1, 200, 400, 600, 800, 999],\n",
    "                   iterations=np.array([0, 1, 2, 3, 5, 7, 10]),\n",
    "                   figsize=(8, 15),\n",
    "                   wspace=0.08,\n",
    "                   hspace=0.02,\n",
    "                   palette=palette)\n",
    "fig.savefig('figures/mnist_shape_iter_examples.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = awesome_plot('multi_mnist', 10, 3, \n",
    "                   example_idxs=[2, 200, 401, 601, 799, 998],\n",
    "                   iterations=np.array([0, 1, 2, 3, 5, 7, 10]),\n",
    "                   figsize=(8, 15),\n",
    "                   wspace=0.08,\n",
    "                   hspace=0.02,\n",
    "                   palette=palette)\n",
    "fig.savefig('figures/multi_mnist_iter_examples.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Loss vs Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient()\n",
    "c = client.binding4.default.runs\n",
    "datasets = {\n",
    "    'Bars': {'config.dataset.name':'bars', 'status': 'COMPLETED'},\n",
    "    'Corners': {'config.dataset.name':'corners', 'status': 'COMPLETED'},\n",
    "    'Shapes': {'config.dataset.name': 'shapes', 'status': 'COMPLETED'},\n",
    "    'MNIST+Shape': {'config.dataset.name': 'mnist_shapes', 'status':'COMPLETED'},\n",
    "    'Multi MNIST': {'config.dataset.name': 'multi_mnist_thresholded', 'status':'COMPLETED'},\n",
    "    'Simple Superposition': {'config.dataset.name': 'easy_superpos', 'status': 'COMPLETED'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_loss = pd.DataFrame()\n",
    "\n",
    "for name, query in datasets.items():\n",
    "    query = copy(query)\n",
    "    query['result'] = {'$gt': 0.1}\n",
    "    print(name, c.find(query).count())\n",
    "    xy = np.array([(r['result'], r['info']['best_val_loss']) for r in c.find(query)])\n",
    "    score_loss = score_loss.append(pd.DataFrame({'Score': xy[:, 0], 'Loss': xy[:, 1], 'Dataset':[name] * xy.shape[0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "facet = sns.lmplot(y='Score', x='Loss', hue='Dataset', data=score_loss, palette='viridis_r', \n",
    "                   legend_out=False, truncate=True, line_kws={'lw':1.5}, #logx=True,\n",
    "                   markers=['o', 'x', '*', 'D', 'v', 's'])\n",
    "facet.fig.set_figwidth(8)\n",
    "facet.fig.set_figheight(5)\n",
    "facet.ax.legend(loc='lower right')\n",
    "\n",
    "#facet.ax.set_xscale('log')\n",
    "facet.ax.set_xlim((0, 200))\n",
    "facet.ax.set_xlabel('Binomial Cross Entropy Error')\n",
    "facet.ax.set_ylabel('Adjusted Mutual Information Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "facet.fig.savefig('figures/score_vs_loss.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = ['simple_superpos', 'mnist_shape', 'multi_mnist', 'shapes', 'corners', 'bars'][::-1]\n",
    "dataset_names = {\n",
    "    'bars': 'Bars',\n",
    "    'corners': 'Corners', \n",
    "    'simple_superpos': 'Simple Superposition',\n",
    "    'mnist_shape': 'MNIST+Shape',\n",
    "    'multi_mnist': 'Multi MNIST',\n",
    "    'shapes': 'Shapes'\n",
    "}\n",
    "Ks = [2, 3, 5, 12]\n",
    "iters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_scores = pd.DataFrame()\n",
    "for ds in datasets:\n",
    "    for k in Ks:\n",
    "        results_filename = \"Results/{}_{}_{}.pickle\".format(ds, iters, k)\n",
    "        if not os.path.exists(results_filename):\n",
    "            print(results_filename)\n",
    "            continue\n",
    "        with open(results_filename, 'rb') as f:\n",
    "            scores = pickle.load(f)[0]\n",
    "            mean_score = scores[:, -1, 0]\n",
    "            pd_score = pd.DataFrame({\n",
    "                    'AMI Score': mean_score,\n",
    "                    '# Clusters': ['{}'.format(k)] * len(mean_score),\n",
    "                    'Dataset': [dataset_names[ds]] * len(mean_score)\n",
    "                })\n",
    "            all_scores = all_scores.append(pd_score, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "sns.barplot(y='Dataset', x='AMI Score', hue=\"# Clusters\", palette='viridis', \n",
    "            order=[dataset_names[ds] for ds in datasets], hue_order=['{}'.format(k) for k in Ks][::-1],\n",
    "            data=all_scores, ax=ax) # errcolor=(0, 0, 0, 0)\n",
    "ax.set_ylabel('')\n",
    "plt.legend(loc=(0.8, 0.2), title='# Clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig.savefig('figures/results.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = 'bars'\n",
    "Ks = [12, 5, 3, 2]\n",
    "iters = 20\n",
    "palette = sns.color_palette(\"viridis\", len(Ks))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "iter_llhs = pd.DataFrame()\n",
    "for i, k in enumerate(Ks):\n",
    "    results_filename = \"Results/{}_{}_{}.pickle\".format(ds, iters, k)\n",
    "    if not os.path.exists(results_filename):\n",
    "        print('missing:', results_filename)\n",
    "        continue\n",
    "        \n",
    "    with open(results_filename, 'rb') as f:\n",
    "        likelihoods = pickle.load(f)[1]\n",
    "        llhs = likelihoods[:, 1:]\n",
    "        m = llhs.mean(0)\n",
    "        s = llhs.std(0)\n",
    "        ax.plot(np.arange(0.5, (len(m)+1)/2, 0.5), m, color=palette[i], label='{}'.format(k))\n",
    "        ax.fill_between(np.arange(0.5, (len(m)+1)/2, 0.5), m+s, m-s, alpha=0.2, color=palette[i])\n",
    "ax.legend(loc='lower right', title='# Clusters')\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Log Likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig.savefig('figures/bars_convergence.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi vs Single Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iters = 20\n",
    "datasets = ['shapes', 'corners', 'bars', 'multi_mnist_thresholded', 'mnist_shapes']\n",
    "dataset_names = {\n",
    "    'bars': 'Bars',\n",
    "    'corners': 'Corners', \n",
    "    'easy_superpos': 'Simple Superposition',\n",
    "    'mnist_shapes': 'MNIST+\\nShape',\n",
    "    'multi_mnist_thresholded': 'Multi\\nMNIST',\n",
    "    'shapes': 'Shapes'\n",
    "}\n",
    "dataset_Ks = {\n",
    "    'bars': 12,\n",
    "    'corners': 5, \n",
    "    'mnist_shapes': 2,\n",
    "    'multi_mnist_thresholded': 3,\n",
    "    'shapes': 3\n",
    "}\n",
    "filenames = {\n",
    "    'multi': \"scores/{}_{}_{}_multi_m.pkl\",\n",
    "    'single': \"scores/{}_{}_{}_long.pkl\"\n",
    "}\n",
    "\n",
    "\n",
    "all_scores = pd.DataFrame()\n",
    "for ds in datasets:\n",
    "    for traint in ['multi', 'single']:\n",
    "        results_filename = filenames[traint].format(ds, iters, dataset_Ks[ds])\n",
    "        if not os.path.exists(results_filename):\n",
    "            print(':(', ds)\n",
    "            continue\n",
    "        with open(results_filename, 'rb') as f:\n",
    "            mean_score = pickle.load(f)[:, -1, :, 0].mean(1)\n",
    "            pd_score = pd.DataFrame({\n",
    "                    'AMI Score': mean_score,\n",
    "                    'Training': [traint] * len(mean_score),\n",
    "                    'Dataset': [dataset_names[ds]] * len(mean_score)\n",
    "                })\n",
    "            all_scores = all_scores.append(pd_score, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 5))\n",
    "sns.barplot(x='Dataset', y='AMI Score', hue=\"Training\", palette='viridis_r', hue_order=['single', 'multi'], \n",
    "            order=[dataset_names[ds] for ds in datasets],\n",
    "            data=all_scores, ax=ax)\n",
    "ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig.savefig('figures/multi_vs_single.pdf', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('shapes_10_3.pkl', 'rb') as f:\n",
    "    scores, results, data, confidences, likelihoods = pickle.load(f)\n",
    "    \n",
    "with h5py.File('/home/greff/Datasets/shapes.h5') as f:\n",
    "    true_groups = f['test']['groups'][:]\n",
    "\n",
    "sort_idxs = np.argsort(scores)\n",
    "scores = scores[sort_idxs]\n",
    "results = results[:, sort_idxs, :]\n",
    "data = data[:, sort_idxs, :]\n",
    "confidences = confidences[sort_idxs]\n",
    "likelihoods = likelihoods[:, sort_idxs]\n",
    "tgroups = true_groups[0, sort_idxs]\n",
    "    \n",
    "if results.shape[-1] != 3:\n",
    "    nr_colors = results.shape[-1]\n",
    "    hsv_colors = np.ones((nr_colors, 3))\n",
    "    hsv_colors[:, 0] = (np.linspace(0, 1, nr_colors, endpoint=False) + 2/3) % 1.0\n",
    "    color_conv = hsv_to_rgb(hsv_colors)\n",
    "    results = results.reshape(-1, nr_colors).dot(color_conv).reshape(results.shape[:-1] + (3,))\n",
    "    \n",
    "net = bs.Network.from_hdf5('networks/shapes_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_img(X, filename, cmap='gray'):\n",
    "    fig, ax = plt.subplots()\n",
    "    if len(X.shape) == 3:\n",
    "        ax.imshow(X, interpolation='nearest')\n",
    "    elif len(X.shape) == 2:\n",
    "        ax.matshow(X, cmap=cmap)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    for s in ['top', 'bottom', 'left', 'right']:\n",
    "        ax.spines[s].set_visible(True)\n",
    "        ax.spines[s].set_linewidth(2)\n",
    "        cm = mpl.cm.get_cmap(cmap)\n",
    "        \n",
    "        ax.spines[s].set_color(cm(0.75))\n",
    "    fig.savefig(filename, bbox_inches='tight', pad_inches=0)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 992\n",
    "\n",
    "init_grp = results[1, i, :, :, 0, :]\n",
    "final_grp = results[2, i, :, :, 0, :]\n",
    "dat = data[0, i, :, :, 0]\n",
    "\n",
    "out = np.zeros_like(init_grp)\n",
    "for k in range(init_grp.shape[-1]):\n",
    "    X = (init_grp[:, :, k]*dat)[None, None, :, :, None]\n",
    "    net.provide_external_data({'default': X} ,all_inputs=False)\n",
    "    net.forward_pass()\n",
    "    Y = net.get(\"Output.outputs.predictions\")   \n",
    "    out[:, :, k] = Y[0, 0, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plot_img(dat, 'figures/alg/01.png', 'gray_r')\n",
    "fig = plot_img(init_grp, 'figures/alg/11.png')\n",
    "for k in range(init_grp.shape[-1]):\n",
    "    fig = plot_img(init_grp[:, :, k]*dat, 'figures/alg/2{}.png'.format(k), cmap=['Reds','Greens','Blues'][k])\n",
    "for k in range(init_grp.shape[-1]):\n",
    "    fig = plot_img(out[:, :, k], 'figures/alg/3{}.png'.format(k), cmap=['Reds','Greens','Blues'][k])\n",
    "fig = plot_img(final_grp, 'figures/alg/41.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
